{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByGXyiHZWM_q"
   },
   "source": [
    "# **Deforum FLUX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "IJjzzkKlWM_s",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown **NVIDIA GPU**\n",
    "import subprocess, os, sys\n",
    "sub_p_res = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total,memory.free', '--format=csv,noheader'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
    "print(f\"{sub_p_res[:-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UA8-efH-WM_t"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown **Environment Setup**\n",
    "import subprocess, time, gc, os, sys\n",
    "\n",
    "!pip install -q -r requirements.txt\n",
    "sys.path.extend(['./deforum_flux', './deforum_flux/src', './x-flux'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "vohUiWo-I2HQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "from IPython import display\n",
    "from types import SimpleNamespace\n",
    "from helpers.save_images import get_output_folder\n",
    "from helpers.settings import load_args\n",
    "from helpers.render import render_animation, render_input_video, render_image_batch, render_interpolation\n",
    "from helpers.prompts import Prompts\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from glob import iglob\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from einops import rearrange\n",
    "from PIL import ExifTags, Image\n",
    "from torchvision import transforms\n",
    "from transformers import pipeline\n",
    "from src.flux.modules.layers import DoubleStreamBlockLoraProcessor\n",
    "from src.flux.sampling import denoise, get_noise, get_schedule, prepare, unpack\n",
    "from src.flux.util import (\n",
    "    configs, \n",
    "    load_ae, \n",
    "    load_clip,\n",
    "    load_flow_model, \n",
    "    load_t5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model: \n",
    "    def __init__(self): \n",
    "        self.dit, self.ae, self.t5, self.clip = self.get_models(\"flux-dev\", 'cuda', offload=False, is_schnell=False)\n",
    "        \n",
    "    def get_models(self, name: str, device: torch.device, offload: bool, is_schnell: bool):\n",
    "        t5 = load_t5(device, max_length=256 if is_schnell else 512)\n",
    "        clip = load_clip(device)\n",
    "        dit = load_flow_model(name, device=\"cpu\" if offload else device)\n",
    "        ae = load_ae(name, device=\"cpu\" if offload else device)\n",
    "        return dit, ae, t5, clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "232_xKcCfIj9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown **Path Setup**\n",
    "def PathSetup():\n",
    "    output_path = \"outputs\" #@param {type:\"string\"}\n",
    "    #      \n",
    "    # models_path = \"./models\" #@param {type:\"string\"}\n",
    "    return locals()\n",
    "\n",
    "root = SimpleNamespace(**PathSetup())\n",
    "\n",
    "#@markdown **Model Setup**\n",
    "def ModelSetup():\n",
    "    custom_config_path = \"\" #@param {type:\"string\"}\n",
    "    custom_checkpoint_path = \"\" #@param {type:\"string\"}\n",
    "    map_location = \"cuda\" #@param [\"cpu\", \"cuda\"]\n",
    "    device = torch.device(map_location)\n",
    "    model = Model()\n",
    "    return locals()\n",
    "\n",
    "root.__dict__.update(ModelSetup())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JxwhBwtWM_t"
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "E0tJVYA4WM_u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DeforumAnimArgs():\n",
    "\n",
    "    #@markdown ####**Animation:**\n",
    "    animation_mode = 'Interpolation' #@param ['None', '2D', '3D', 'Video Input', 'Interpolation'] {type:'string'}\n",
    "    max_frames = 1000 #@param {type:\"number\"}\n",
    "    border = 'replicate' #@param ['wrap', 'replicate'] {type:'string'}\n",
    "\n",
    "    #@markdown ####**Motion Parameters:**\n",
    "    angle = \"0:(0)\"#@param {type:\"string\"}\n",
    "    zoom = \"0:(1.04)\"#@param {type:\"string\"}\n",
    "    translation_x = \"0:(0)\"#@param {type:\"string\"}\n",
    "    translation_y = \"0:(0)\"#@param {type:\"string\"}\n",
    "    translation_z = \"0:(7.5)\"#@param {type:\"string\"}\n",
    "    rotation_3d_x = \"0:(0)\"#@param {type:\"string\"}\n",
    "    rotation_3d_y = \"0:(0)\"#@param {type:\"string\"}\n",
    "    rotation_3d_z = \"0:(0)\"#@param {type:\"string\"}\n",
    "    flip_2d_perspective = False #@param {type:\"boolean\"}\n",
    "    perspective_flip_theta = \"0:(0)\"#@param {type:\"string\"}\n",
    "    perspective_flip_phi = \"0:(t%15)\"#@param {type:\"string\"}\n",
    "    perspective_flip_gamma = \"0:(0)\"#@param {type:\"string\"}\n",
    "    perspective_flip_fv = \"0:(53)\"#@param {type:\"string\"}\n",
    "    noise_schedule = \"0: (0.02)\"#@param {type:\"string\"}\n",
    "    # strength_schedule = \"0: (0.65), 24: (0.65), 25: (0.8), 47: (0.8), 48: (0.65)\"#@param {type:\"string\"}\n",
    "    strength_schedule = \"0: (0.65), 12: (0.70), 24: (0.8), 36: (0.85), 38: (0.65)\"\n",
    "    contrast_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
    "    hybrid_comp_alpha_schedule = \"0:(1)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_blend_alpha_schedule = \"0:(0.5)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_contrast_schedule = \"0:(1)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_auto_contrast_cutoff_high_schedule =  \"0:(100)\" #@param {type:\"string\"}\n",
    "    hybrid_comp_mask_auto_contrast_cutoff_low_schedule =  \"0:(0)\" #@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Sampler Scheduling:**\n",
    "    enable_schedule_samplers = False #@param {type:\"boolean\"}\n",
    "    sampler_schedule = \"0:('Default Flux Scheduler')\" #@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Unsharp mask (anti-blur) Parameters:**\n",
    "    kernel_schedule = \"0: (5)\"#@param {type:\"string\"}\n",
    "    sigma_schedule = \"0: (1.0)\"#@param {type:\"string\"}\n",
    "    amount_schedule = \"0: (0.2)\"#@param {type:\"string\"}\n",
    "    threshold_schedule = \"0: (0.0)\"#@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Coherence:**\n",
    "    color_coherence = 'Match Frame 0 RGB' #@param ['None', 'Match Frame 0 HSV', 'Match Frame 0 LAB', 'Match Frame 0 RGB', 'Video Input'] {type:'string'}\n",
    "    color_coherence_video_every_N_frames = 1 #@param {type:\"integer\"}\n",
    "    color_force_grayscale = False #@param {type:\"boolean\"}\n",
    "    diffusion_cadence = '1' #@param ['1','2','3','4','5','6','7','8'] {type:'string'}\n",
    "\n",
    "    #@markdown ####**3D Depth Warping:**\n",
    "    use_depth_warping = True #@param {type:\"boolean\"}\n",
    "    midas_weight = 0.3#@param {type:\"number\"}\n",
    "    near_plane = 200\n",
    "    far_plane = 10000\n",
    "    fov = 40#@param {type:\"number\"}\n",
    "    padding_mode = 'border'#@param ['border', 'reflection', 'zeros'] {type:'string'}\n",
    "    sampling_mode = 'bicubic'#@param ['bicubic', 'bilinear', 'nearest'] {type:'string'}\n",
    "    save_depth_maps = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown ####**Video Input:**\n",
    "    video_init_path ='/content/video_in.mp4'#@param {type:\"string\"}\n",
    "    extract_nth_frame = 1#@param {type:\"number\"}\n",
    "    overwrite_extracted_frames = True #@param {type:\"boolean\"}\n",
    "    use_mask_video = False #@param {type:\"boolean\"}\n",
    "    video_mask_path ='/content/video_in.mp4'#@param {type:\"string\"}\n",
    "\n",
    "    #@markdown ####**Hybrid Video for 2D/3D Animation Mode:**\n",
    "    hybrid_generate_inputframes = False #@param {type:\"boolean\"}\n",
    "    hybrid_use_first_frame_as_init_image = True #@param {type:\"boolean\"}\n",
    "    hybrid_motion = \"None\" #@param ['None','Optical Flow','Perspective','Affine']\n",
    "    hybrid_motion_use_prev_img = False #@param {type:\"boolean\"}\n",
    "    hybrid_flow_method = \"DIS Medium\" #@param ['DenseRLOF','DIS Medium','Farneback','SF']\n",
    "    hybrid_composite = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_mask_type = \"None\" #@param ['None', 'Depth', 'Video Depth', 'Blend', 'Difference']\n",
    "    hybrid_comp_mask_inverse = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_mask_equalize = \"None\" #@param  ['None','Before','After','Both']\n",
    "    hybrid_comp_mask_auto_contrast = False #@param {type:\"boolean\"}\n",
    "    hybrid_comp_save_extra_frames = False #@param {type:\"boolean\"}\n",
    "    hybrid_use_video_as_mse_image = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown ####**Interpolation:**\n",
    "    interpolate_key_frames = False #@param {type:\"boolean\"}\n",
    "    interpolate_x_frames = 32 #@param {type:\"number\"}\n",
    "    \n",
    "    #@markdown ####**Resume Animation:**\n",
    "    resume_from_timestring = False #@param {type:\"boolean\"}\n",
    "    resume_timestring = \"20240810001544\" #@param {type:\"string\"}\n",
    "\n",
    "    return locals()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9fly1RIWM_u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prompts\n",
    "prompts = {\n",
    "    0: \"super realism, 4k, a highly detailed close-up view of a woman's mesmerizing blue eye, with realistic reflections and an intense natural sparkle. The iris displays intricate patterns of deep blues and subtle hints of lighter hues, while delicate veins add to the eye's natural complexity. Soft, diffused lighting enhances the eye's depth, with a blurred background to emphasize the eye's captivating beauty and detail.\",\n",
    "    12: \"super realism, 4k, the woman's blue eye transforms into a stunning cosmic scene. Tiny, luminous stars begin to appear within the iris, creating a sense of depth. Nebulae with swirling, ethereal colors—rich purples, blues, and pinks—emerge, blending seamlessly with the natural textures of the eye. The transition is smooth, with the cosmic elements gradually overtaking the eye's surface, adding a layer of wonder and vastness.\",\n",
    "    24: \"super realism, 4k, grand cosmic vista contained within the eye. The eye now features swirling galaxies with vibrant, spiraling arms, and floating celestial bodies such as distant planets and shimmering asteroids. Nebulae continue to swirl with dynamic, vivid colors, creating a surreal and expansive universe that feels both infinite and intimately contained within the eye's bounds.\",\n",
    "    36: \"super realism, 4k, The swirling galaxies and celestial bodies are now accompanied by pulsating stars and radiant supernovae, with intricate light effects and a sense of motion. The smooth transition ensures that the cosmic wonder within the eye remains captivating and visually coherent.\",\n",
    "}\n",
    "\n",
    "# can be a string, list, or dictionary\n",
    "# prompts = [\n",
    "#    # \"a beautiful lake by Asher Brown Durand, trending on Artstation\",\n",
    "#    \"a beautiful portrait of a woman by Artgerm, trending on Artstation\",\n",
    "# ]\n",
    "#prompts = \"a beautiful lake by Asher Brown Durand, trending on Artstation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "XVzhbmizWM_u",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown **Load Settings**\n",
    "override_settings_with_file = False #@param {type:\"boolean\"}\n",
    "settings_file = \"custom\" #@param [\"custom\", \"512x512_aesthetic_0.json\",\"512x512_aesthetic_1.json\",\"512x512_colormatch_0.json\",\"512x512_colormatch_1.json\",\"512x512_colormatch_2.json\",\"512x512_colormatch_3.json\"]\n",
    "custom_settings_file = \"/content/drive/MyDrive/Settings.txt\"#@param {type:\"string\"}\n",
    "\n",
    "def DeforumArgs():\n",
    "    #@markdown **Image Settings**\n",
    "    W = 1024 #@param\n",
    "    H = 1024 #@param\n",
    "    W, H = map(lambda x: x - x % 64, (W, H))  # resize to integer multiple of 64\n",
    "    bit_depth_output = 8 #@param [8, 16, 32] {type:\"raw\"}\n",
    "\n",
    "    #@markdown **Sampling Settings**\n",
    "    seed = -1 #@param\n",
    "    sampler = 'Flux Default Sampler' # sampler schedule is not supported\n",
    "    steps = 30 #@param\n",
    "    scale = 3.5 #@param\n",
    "    dynamic_threshold = None\n",
    "    static_threshold = None   \n",
    "\n",
    "    #@markdown **Save & Display Settings**\n",
    "    save_samples = True #@param {type:\"boolean\"}\n",
    "    save_settings = True #@param {type:\"boolean\"}\n",
    "    display_samples = True #@param {type:\"boolean\"}\n",
    "    save_sample_per_step = False #@param {type:\"boolean\"}\n",
    "    show_sample_per_step = False #@param {type:\"boolean\"}\n",
    "\n",
    "    #@markdown **Batch Settings**\n",
    "    n_batch = 1 #@param\n",
    "    n_samples = 1 #@param\n",
    "    batch_name = \"StableFun\" #@param {type:\"string\"}\n",
    "    filename_format = \"{timestring}_{index}_{prompt}.png\" #@param [\"{timestring}_{index}_{seed}.png\",\"{timestring}_{index}_{prompt}.png\"]\n",
    "    seed_behavior = \"iter\" #@param [\"iter\",\"fixed\",\"random\",\"ladder\",\"alternate\"]\n",
    "    seed_iter_N = 1 #@param {type:'integer'}\n",
    "    make_grid = False #@param {type:\"boolean\"}\n",
    "    grid_rows = 2 #@param \n",
    "    outdir = get_output_folder(root.output_path, batch_name)\n",
    "\n",
    "    #@markdown **Init Settings**\n",
    "    use_init = False #@param {type:\"boolean\"}\n",
    "    strength = 1.0 #@param {type:\"number\"}\n",
    "    strength_0_no_init = True # Set the strength to 0 automatically when no init image is used\n",
    "    init_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
    "    add_init_noise = False #@param {type:\"boolean\"}\n",
    "    init_noise = 0.01 #@param\n",
    "    # Whiter areas of the mask are areas that change more\n",
    "    use_mask = False #@param {type:\"boolean\"}\n",
    "    use_alpha_as_mask = False # use the alpha channel of the init image as the mask\n",
    "    mask_file = \"https://www.filterforge.com/wiki/images/archive/b/b7/20080927223728%21Polygonal_gradient_thumb.jpg\" #@param {type:\"string\"}\n",
    "    invert_mask = False #@param {type:\"boolean\"}\n",
    "    # Adjust mask image, 1.0 is no adjustment. Should be positive numbers.\n",
    "    mask_brightness_adjust = 1.0  #@param {type:\"number\"}\n",
    "    mask_contrast_adjust = 1.0  #@param {type:\"number\"}\n",
    "    # Overlay the masked image at the end of the generation so it does not get degraded by encoding and decoding\n",
    "    overlay_mask = True  # {type:\"boolean\"}\n",
    "    # Blur edges of final overlay mask, if used. Minimum = 0 (no blur)\n",
    "    mask_overlay_blur = 5 # {type:\"number\"}\n",
    "\n",
    "    #@markdown **Exposure/Contrast Conditional Settings**\n",
    "    mean_scale = 0 #@param {type:\"number\"}\n",
    "    var_scale = 0 #@param {type:\"number\"}\n",
    "    exposure_scale = 0 #@param {type:\"number\"}\n",
    "    exposure_target = 0.5 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **Color Match Conditional Settings**\n",
    "    colormatch_scale = 0 #@param {type:\"number\"}\n",
    "    colormatch_image = \"https://www.saasdesign.io/wp-content/uploads/2021/02/palette-3-min-980x588.png\" #@param {type:\"string\"}\n",
    "    # colormatch_image = None\n",
    "    colormatch_n_colors = 4 #@param {type:\"number\"}\n",
    "    ignore_sat_weight = 0 #@param {type:\"number\"}\n",
    "\n",
    "    #@markdown **Other Conditional Settings**\n",
    "    init_mse_scale = 0 #@param {type:\"number\"}\n",
    "    init_mse_image = \"https://cdn.pixabay.com/photo/2022/07/30/13/10/green-longhorn-beetle-7353749_1280.jpg\" #@param {type:\"string\"}\n",
    "    blue_scale = 0 #@param {type:\"number\"}\n",
    "    \n",
    "    #@markdown **Conditional Gradient Settings**\n",
    "    gradient_wrt = 'x0_pred' #@param [\"x\", \"x0_pred\"]\n",
    "    gradient_add_to = 'both' #@param [\"cond\", \"uncond\", \"both\"]\n",
    "    decode_method = 'linear' #@param [\"autoencoder\",\"linear\"]\n",
    "    grad_threshold_type = 'dynamic' #@param [\"dynamic\", \"static\", \"mean\", \"schedule\"]\n",
    "    clamp_grad_threshold = 0.2 #@param {type:\"number\"}\n",
    "    clamp_start = 0.2 #@param\n",
    "    clamp_stop = 0.01 #@param\n",
    "    grad_inject_timing = list(range(1,10)) #@param\n",
    "\n",
    "    #@markdown **Speed vs VRAM Settings**\n",
    "    cond_uncond_sync = True #@param {type:\"boolean\"}\n",
    "    precision = 'autocast' \n",
    "    C = 4\n",
    "    f = 8\n",
    "\n",
    "    cond_prompt = \"\"\n",
    "    cond_prompts = \"\"\n",
    "    uncond_prompt = \"\"\n",
    "    uncond_prompts = \"\"\n",
    "    timestring = \"\"\n",
    "    init_latent = None\n",
    "    init_sample = None\n",
    "    init_sample_raw = None\n",
    "    mask_sample = None\n",
    "    init_c = None\n",
    "    seed_internal = 0\n",
    "\n",
    "    return locals()\n",
    "\n",
    "args_dict = DeforumArgs()\n",
    "anim_args_dict = DeforumAnimArgs()\n",
    "\n",
    "if override_settings_with_file:\n",
    "    load_args(args_dict, anim_args_dict, settings_file, custom_settings_file, verbose=False)\n",
    "\n",
    "args = SimpleNamespace(**args_dict)\n",
    "anim_args = SimpleNamespace(**anim_args_dict)\n",
    "\n",
    "args.timestring = time.strftime('%Y%m%d%H%M%S')\n",
    "args.strength = max(0.0, min(1.0, args.strength))\n",
    "\n",
    "if args.seed == -1:\n",
    "    args.seed = random.randint(0, 2**32 - 1)\n",
    "if not args.use_init:\n",
    "    args.init_image = None\n",
    "    \n",
    "if anim_args.animation_mode == 'None':\n",
    "    anim_args.max_frames = 1\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    args.use_init = True\n",
    "\n",
    "# clean up unused memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# get prompts\n",
    "cond, uncond = Prompts(prompt=prompts).as_dict()\n",
    "\n",
    "# dispatch to appropriate renderer\n",
    "if anim_args.animation_mode == '2D' or anim_args.animation_mode == '3D':\n",
    "    render_animation(root, anim_args, args, cond, uncond)\n",
    "elif anim_args.animation_mode == 'Video Input':\n",
    "    render_input_video(root, anim_args, args, uncond)\n",
    "elif anim_args.animation_mode == 'Interpolation':\n",
    "    render_interpolation(root, anim_args, args, cond, uncond)\n",
    "else:\n",
    "    render_image_batch(root, args, cond, uncond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJ88kZ2-WM_v"
   },
   "source": [
    "# Create Video From Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@markdown **New Version**\n",
    "skip_video_for_run_all = False #@param {type: 'boolean'}\n",
    "create_gif = False #@param {type: 'boolean'}\n",
    "\n",
    "if skip_video_for_run_all == True:\n",
    "    print('Skipping video creation, uncheck skip_video_for_run_all if you want to run it')\n",
    "else:\n",
    "\n",
    "    from helpers.ffmpeg_helpers import get_extension_maxframes, get_auto_outdir_timestring, get_ffmpeg_path, make_mp4_ffmpeg, make_gif_ffmpeg, patrol_cycle\n",
    "\n",
    "    def ffmpegArgs():\n",
    "        ffmpeg_mode = \"auto\" #@param [\"auto\",\"manual\",\"timestring\"]\n",
    "        ffmpeg_outdir = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_timestring = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_image_path = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_mp4_path = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_gif_path = \"\" #@param {type:\"string\"}\n",
    "        ffmpeg_extension = \"png\" #@param {type:\"string\"}\n",
    "        ffmpeg_maxframes = 200 #@param\n",
    "        ffmpeg_fps = 12 #@param\n",
    "\n",
    "        # determine auto paths\n",
    "        if ffmpeg_mode == 'auto':\n",
    "            ffmpeg_outdir, ffmpeg_timestring = get_auto_outdir_timestring(args,ffmpeg_mode)\n",
    "        if ffmpeg_mode in [\"auto\",\"timestring\"]:\n",
    "            ffmpeg_extension, ffmpeg_maxframes = get_extension_maxframes(args,ffmpeg_outdir,ffmpeg_timestring)\n",
    "            ffmpeg_image_path, ffmpeg_mp4_path, ffmpeg_gif_path = get_ffmpeg_path(ffmpeg_outdir, ffmpeg_timestring, ffmpeg_extension)\n",
    "        return locals()\n",
    "\n",
    "    ffmpeg_args_dict = ffmpegArgs()\n",
    "    ffmpeg_args = SimpleNamespace(**ffmpeg_args_dict)\n",
    "    make_mp4_ffmpeg(ffmpeg_args, display_ffmpeg=True, debug=False)\n",
    "    if create_gif:\n",
    "        make_gif_ffmpeg(ffmpeg_args, debug=False)\n",
    "    #patrol_cycle(args,ffmpeg_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vL8nOkac767"
   },
   "source": [
    "# Disconnect Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "MMpAcyrYWM_v",
    "tags": []
   },
   "outputs": [],
   "source": [
    "skip_disconnect_for_run_all = True #@param {type: 'boolean'}\n",
    "\n",
    "if skip_disconnect_for_run_all == True:\n",
    "    print('Skipping disconnect, uncheck skip_disconnect_for_run_all if you want to run it')\n",
    "else:\n",
    "    from google.colab import runtime\n",
    "    runtime.unassign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "25b221746895226ff7c6b9d8aea8c62a9e808c88b786315a5ba5e4e82d158d3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
